---
output: github_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "figs/",
  fig.height = 3,
  fig.width = 4,
  fig.align = "center"
)
```

[\@drsimonj](https://twitter.com/drsimonj) here to show you how to use pipelearner to easily grid-search hyperparameters for a model.

pipelearner is a package for making machine learning piplines and is currently available to install from GitHub by running the following:

```{r init-example, message = FALSE, eval = F}
# install.packages("devtools")  # Run this if devtools isn't installed
devtools::install_github("drsimonj/pipelearner")
library(pipelearner)
```
```{r, echo = F}
library(pipelearner)
```

In this post we'll grid search hyperparameters of a decision tree (using the rpart package) predicting cars' transmission type (automatic or manual) using the mtcars data set. Let's load rpart along with tidyverse, which pipelearner is intended to work with:

```{r, message = F}
library(tidyverse)
library(rpart)
```

### The data

Quickly convert our outcome variable to a factor with proper labels:

```{r}
d <- mtcars %>% 
  mutate(am = factor(am, labels = c("automatic", "manual")))
head(d)
```

## Default hyperparameters

We'll first create a pipelearner object that uses the default hyperparameters of the decision tree.

```{r}
pl <- d %>% pipelearner(rpart, am ~ .)
pl
```

Fit the model with `learn()`:

```{r}
results <- pl %>% learn()
results
```

The fitted results include our single model. Let's assess the model's performance on the training and test sets:

```{r}
# Function to compute accuracy
accuracy <- function(fit, data, target_var) {
  # Coerce `data` to data.frame (needed for resample objects)
  data <- as.data.frame(data)
  # Obtain predicted class
  predicted <- predict(fit, data, type = "class")
  # Return accuracy
  mean(predicted == data[[target_var]])
}

# Training accuracy
accuracy(results$fit[[1]], results$train[[1]], results$target[[1]])

# Test accuracy
accuracy(results$fit[[1]], results$test[[1]], results$target[[1]])
```

Looks like we've achieved `r round(100*accuracy(results$fit[[1]], results$train[[1]], results$target[[1]]))`% accuracy on the training data and `r round(100*accuracy(results$fit[[1]], results$test[[1]], results$target[[1]]))`% accuracy on the test data. Perhaps we can improve on this by tweaking the model's hyperparameters.

## Adding hyperparameters

When using pipelearner, you can add any arguments that the learning function will accept after we provide a formula. For example, run `?rpart` and you'll see that control options can be added. To see these options, run `?rpart.control`.

An obvious choice for decision trees is `minsplit`, which determines "the minimum number of observations that must exist in a node in order for a split to be attempted." By default it's set to 20. Given that we have such a small data set, this seems like a poor choice. We can adjust it as follows:

```{r}
pl <- d %>% pipelearner(rpart, am ~ ., minsplit = 5)
results <- pl %>% learn()

# Training accuracy
accuracy(results$fit[[1]], results$train[[1]], results$target[[1]])

# Test accuracy
accuracy(results$fit[[1]], results$test[[1]], results$target[[1]])
```

Reducing `minsplit` will generally increase your training accuracy. Too small, however, and you'll overfit the training data resulting in poorer test accuracy.

## Using vectors

All the model arguments you provide to `pipelearner()` can be vectors. pipelearner will then automatically expand those vectors into a grid and test all combinations. For example, let's try out many values for `minsplit`:

```{r}
pl <- d %>% pipelearner(rpart, am ~ ., minsplit = c(2, 4, 6, 8, 10))
results <- pl %>% learn()
results
```

Combining `mutate` from dplyr and `map` functions from the purrr package (all loaded with tidyverse), we can extract the relevant information for each value of `minsplit`:

```{r}
results <- results %>% 
  mutate(
    minsplit = map_dbl(params, "minsplit"),
    accuracy_train = pmap_dbl(list(fit, train, target), accuracy),
    accuracy_test  = pmap_dbl(list(fit, test,  target), accuracy)
  )

results %>% select(minsplit, contains("accuracy"))
```

This applies to as many hyperparameters as you care to add. For example, let's grid search combinations of values for `minsplit`, `maxdepth`, and `xval`:

```{r}
pl <- d %>% pipelearner(rpart, am ~ .,
                        minsplit = c(2, 20),
                        maxdepth = c(2, 5),
                        xval     = c(5, 10))
pl %>%
  learn()%>% 
  mutate(
    minsplit = map_dbl(params, "minsplit"),
    maxdepth = map_dbl(params, "maxdepth"),
    xval     = map_dbl(params, "xval"),
    accuracy_train = pmap_dbl(list(fit, train, target), accuracy),
    accuracy_test  = pmap_dbl(list(fit, test,  target), accuracy)
  ) %>%
  select(minsplit, maxdepth, xval, contains("accuracy"))
```

Not much variance in the accuracy, but it demonstrates how you can use this in your own work.

## Using train_models()

A bonus tip for those of you how are comfortable so far: you can use `learn_models()` to isolate multiple grid searches. For example:

```{r}
pl <- d %>%
  pipelearner() %>% 
  learn_models(rpart, am ~ ., minsplit = c(1, 2), maxdepth = c(4, 5)) %>% 
  learn_models(rpart, am ~ ., minsplit = c(6, 7), maxdepth = c(1, 2))
  
pl %>%
  learn()%>% 
  mutate(
    minsplit = map_dbl(params, "minsplit"),
    maxdepth = map_dbl(params, "maxdepth"),
    accuracy_train = pmap_dbl(list(fit, train, target), accuracy),
    accuracy_test  = pmap_dbl(list(fit, test,  target), accuracy)
  ) %>%
  select(minsplit, maxdepth, contains("accuracy"))
```

Notice the separate grid searches for `minsplit = c(1, 2), maxdepth = c(4, 5)` and `minsplit = c(6, 7), maxdepth = c(1, 2)`. This is because grid search is applied separately for each model defined by a `learn_models()` call. This means you can separate various hyperparameters combinations if you want to.

## Sign off

Thanks for reading and I hope this was useful for you.

For updates of recent blog posts, follow [\@drsimonj](https://twitter.com/drsimonj) on Twitter, or email me at <drsimonjackson@gmail.com> to get in touch.

If you'd like the code that produced this blog, check out the [blogR GitHub repository](https://github.com/drsimonj/blogR).
